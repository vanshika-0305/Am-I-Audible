# -*- coding: utf-8 -*-
"""siamese_network_v1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sgv1dgeah5J0_ZgkB_AoiAjiGWHzjQdg
"""

from google.colab import drive
import tensorflow as tf
import pickle

# Mount Google Drive
drive.mount('/content/drive')


# Load model
model_load_path = "/content/drive/MyDrive/cnn_speaker_classifier.h5"
model = tf.keras.models.load_model(model_load_path)

print("Model loaded successfully!")

# Load label encoder
le_load_path = "/content/drive/MyDrive/label_encoder.pkl"

with open(le_load_path, 'rb') as f:
    le = pickle.load(f)

print("Label Encoder loaded successfully!")

import tensorflow as tf
from tensorflow.keras import layers, Model, backend as K
import numpy as np
import librosa
import pickle
import os
import random

import tensorflow as tf
from tensorflow.keras import layers, Model, backend as K
import numpy as np
import librosa
import pickle
import os
import random
def siamese_network():
    input_shape = (128, 128, 1)
    input_a = layers.Input(shape=input_shape)
    input_b = layers.Input(shape=input_shape)

    # Pass both inputs through the shared CNN feature extractor
    encoded_a = feature_extractor(input_a)
    encoded_b = feature_extractor(input_b)

    l1_distance = layers.Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))([encoded_a, encoded_b])

    dense1 = layers.Dense(128, activation='relu')(l1_distance)
    dense2 = layers.Dense(64, activation='relu')(dense1)
    output = layers.Dense(1, activation='sigmoid')(dense2)  # 1 = same speaker, 0 = different speakers

    model = Model(inputs=[input_a, input_b], outputs=output)
    return model

siamese_model = siamese_network()
siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
siamese_model.summary()

import tensorflow as tf
from tensorflow.keras.models import Model
import numpy as np

dummy_input = np.random.random((1, 128, 128, 1))  # Adjust the shape to match your model's input shape
_ = model(dummy_input)  # This builds the model

feature_extractor = Model(inputs=model.inputs, outputs=model.layers[-2].output)
feature_extractor.trainable = False
print("Feature Extractor Summary:")
feature_extractor.summary()

import os

# Define the data directory
data_dir = '/content/drive/MyDrive/Datasets/vox_indian'

# Get the list of speaker directories (e.g., id11071, id11072, etc.)
speaker_dirs = [f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))]

# Process each speaker directory
speaker_files = {}
for speaker_dir in speaker_dirs:
    speaker_path = os.path.join(data_dir, speaker_dir)
    session_dirs = [f for f in os.listdir(speaker_path) if os.path.isdir(os.path.join(speaker_path, f))]
    speaker_files[speaker_dir] = {}

    # Process each session directory
    for session_dir in session_dirs:
        session_path = os.path.join(speaker_path, session_dir)
        files = [f for f in os.listdir(session_path) if os.path.isfile(os.path.join(session_path, f))]
        speaker_files[speaker_dir][session_dir] = files

# Print speaker_files for debugging
print("Speaker Files:")
for speaker, sessions in speaker_files.items():
    print(f"Speaker: {speaker}")
    for session, files in sessions.items():
        print(f"  Session: {session}")
        for file in files:
            print(f"    File: {file}")

# Generate positive and negative pairs
positive_pairs = []
negative_pairs = []

# Example: Generate positive pairs (files from the same session)
for speaker, sessions in speaker_files.items():
    for session, files in sessions.items():
        if len(files) >= 2:  # Ensure there are at least 2 files in the session
            file1 = os.path.join(data_dir, speaker, session, files[0])
            file2 = os.path.join(data_dir, speaker, session, files[1])
            if os.path.exists(file1) and os.path.exists(file2):
                positive_pairs.append((file1, file2))
            else:
                print(f"File not found: {file1} or {file2}")

# Example: Generate negative pairs (files from different speakers)
speakers = list(speaker_files.keys())
for i in range(len(speakers)):
    for j in range(i + 1, len(speakers)):
        speaker1 = speakers[i]
        speaker2 = speakers[j]
        sessions1 = list(speaker_files[speaker1].keys())
        sessions2 = list(speaker_files[speaker2].keys())

        if len(sessions1) >= 1 and len(sessions2) >= 1:
            file1 = os.path.join(data_dir, speaker1, sessions1[0], speaker_files[speaker1][sessions1[0]][0])
            file2 = os.path.join(data_dir, speaker2, sessions2[0], speaker_files[speaker2][sessions2[0]][0])
            if os.path.exists(file1) and os.path.exists(file2):
                negative_pairs.append((file1, file2))
            else:
                print(f"File not found: {file1} or {file2}")

# Print the generated pairs
print("\nPositive Pairs:")
for pair in positive_pairs:
    print(pair)

print("\nNegative Pairs:")
for pair in negative_pairs:
    print(pair)

pairs=positive_pairs+negative_pairs

import os
import random

def create_siamese_pairs(data_dir):
    # Get the list of speaker directories (i.e., id1001, id1002, etc.)
    speakers = [s for s in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, s))]
    speaker_files = {}

    for speaker in speakers:
        speaker_path = os.path.join(data_dir, speaker)
        sessions = os.listdir(speaker_path)  # Get sessions inside the speaker's directory
        speaker_files[speaker] = []

        for session in sessions:
            session_path = os.path.join(speaker_path, session)
            if os.path.isdir(session_path):
                files = [f for f in os.listdir(session_path) if os.path.isfile(os.path.join(session_path, f))]
                full_paths = [os.path.join(session_path, f) for f in files]
                speaker_files[speaker].extend(full_paths)  # Store full file paths for the speaker

    positive_pairs = []
    negative_pairs = []
    labels = []

    # Create positive pairs (same speaker, different recordings)
    for speaker, files in speaker_files.items():
        if len(files) > 1:  # Ensure there are at least two recordings
            for i in range(len(files) - 1):
                positive_pairs.append((files[i], files[i+1]))
                labels.append(1)

    # Create negative pairs (different speakers)
    speaker_list = list(speaker_files.keys())
    for _ in range(len(positive_pairs)):  # Ensure equal number of negative pairs
        speaker1, speaker2 = random.sample(speaker_list, 2)  # Pick two different speakers
        if speaker_files[speaker1] and speaker_files[speaker2]:  # Ensure both have files
            file1 = random.choice(speaker_files[speaker1])
            file2 = random.choice(speaker_files[speaker2])
            negative_pairs.append((file1, file2))
            labels.append(0)

    # Combine positive and negative pairs
    all_pairs = positive_pairs + negative_pairs
    print(f"Total pairs created: {len(all_pairs)}")  # Debugging: Check total number of pairs
    return all_pairs, labels

data_dir = "/content/drive/MyDrive/Datasets/vox_indian/"
pairs, labels = create_siamese_pairs(data_dir)

# Debugging: Check the result
print(f"Number of pairs: {len(pairs)}")
print(f"Number of labels: {len(labels)}")
print("\nSample Pairs:")
for i in range(5):  # Print first 5 pairs
    print(pairs[i], "Label:", labels[i])

import librosa
import numpy as np
import tensorflow as tf
import os
import traceback

def preprocess_audio(file_path, target_shape=(128, 128), sr=16000):
    try:
        if not os.path.exists(file_path):
            print(f"File not found: {file_path}")
            return None

        print(f"Processing: {file_path}")

        y, _ = librosa.load(file_path, sr=sr)
        print(f"Loaded audio shape: {y.shape}")
        y = librosa.util.fix_length(y, size=3 * sr)

        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=target_shape[0], hop_length=512)
        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)
        print(f"Mel spectrogram shape: {mel_spec_db.shape}")

        mel_spec_db = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-6)    #min max normalization here (0 <-> 1)
        mel_spec_db = tf.image.resize(mel_spec_db[None, :,:, None], target_shape[:2]).numpy().squeeze()     #resizing and remove unnecessary
        print(f"Resized shape: {mel_spec_db.shape}")

        mel_spec_db = mel_spec_db[:,:, np.newaxis]    #adds channel dimension , so basically converting our 2d spectogram into a 3d tensor for our cnn to understand

        print("Processing successful!\n")
        return np.expand_dims(mel_spec_db, axis=0) #Reshape to (batch_size,128,128,1) as it is accepting a 4d tensor

    except Exception as e:
        print(f"Error processing {file_path}: {str(e)}")
        traceback.print_exc()  # Print full error traceback
        return None

def pad_spectrogram(spectrogram, target_shape=(128, 128)):
    rows, cols = spectrogram.shape[:2]
    pad_height = max(0, target_shape[0] - rows) #height for making 128
    pad_width = max(0, target_shape[1] - cols)  #Widht for making 128. overall padded to 128 x 128 if necessary

    padded_spectrogram = np.pad(spectrogram, ((0, pad_height), (0, pad_width), (0, 0)), mode='constant')
    return padded_spectrogram

import os

dataset_path = "/content/drive/MyDrive/Datasets/vox_indian/"
for speaker_id in os.listdir(dataset_path):
    speaker_path = os.path.join(dataset_path, speaker_id)
    if os.path.isdir(speaker_path):
        print(f"Speaker {speaker_id}: {os.listdir(speaker_path)}")

# Before processing, filter out invalid pairs
valid_pairs = []
valid_labels = []

for file1, file2 in pairs:
    if os.path.exists(file1) and os.path.exists(file2):
        valid_pairs.append((file1, file2))
    else:
        print(f"Skipping pair: {file1} | {file2}")

print(f"Found {len(valid_pairs)} valid pairs out of {len(pairs)}")

# Step 1: Generate pairs only for existing files
valid_pairs = []
for file1, file2 in pairs:  # Change original_pairs to pairs
    if os.path.exists(file1) and os.path.exists(file2):
        valid_pairs.append((file1, file2))
    else:
        print(f"Skipping invalid pair: {file1} | {file2}")

X1 = []
X2 = []
y_cleaned = []

for i, (file1, file2) in enumerate(pairs):
    if not os.path.exists(file1):
        print(f"File not found: {file1}")
        continue
    if not os.path.exists(file2):
        print(f"File not found: {file2}")
        continue
    x1 = preprocess_audio(file1)
    x2 = preprocess_audio(file2)
    if x1 is not None and x2 is not None:
        x1 = pad_spectrogram(x1[0])
        x2 = pad_spectrogram(x2[0])

        X1.append(x1)
        X2.append(x2)
        y_cleaned.append(labels[i])

X1 = np.array(X1)
X2 = np.array(X2)
y = np.array(y_cleaned)


# Reshape X1 and X2 before fitting
X1 = X1.reshape(-1, 128, 128, 1)  # Reshape to (num_samples, 128, 128, 1)
X2 = X2.reshape(-1, 128, 128, 1)  # Reshape to (num_samples, 128, 128, 1)

print(f"Processed {len(X1)} valid pairs out of {len(pairs)} total pairs.")

X1 = np.array([preprocess_audio(p[0]) for p in pairs])
X2 = np.array([preprocess_audio(p[1]) for p in pairs])
y = np.array(labels)

# Remove None values (failed audio files)
valid_idx = [i for i in range(len(X1)) if X1[i] is not None and X2[i] is not None]
X1 = np.array([X1[i] for i in valid_idx])
X2 = np.array([X2[i] for i in valid_idx])
y = np.array([y[i] for i in valid_idx])

X1 = np.squeeze(X1, axis=1)  # Remove unnecessary dimension
X2 = np.squeeze(X2, axis=1)
y = y.reshape(-1, 1)  # Ensure labels are in correct shape (num_samples, 1)

print(f"X1 shape: {X1.shape}, X2 shape: {X2.shape}, y shape: {y.shape}")

import numpy as np
import tensorflow as tf

# Ensure data is non-empty
if len(X1) == 0 or len(X2) == 0 or len(y) == 0:
    raise ValueError("Error: One or more datasets are empty after preprocessing!")

# Convert to float32
X1 = np.array(X1, dtype=np.float32)
X2 = np.array(X2, dtype=np.float32)
y = np.array(y, dtype=np.float32).reshape(-1, 1)

# Convert to tensors
X1_tensor = tf.convert_to_tensor(X1, dtype=tf.float32)
X2_tensor = tf.convert_to_tensor(X2, dtype=tf.float32)
y_tensor = tf.convert_to_tensor(y, dtype=tf.float32)
print(siamese_model.input_shape)

siamese_model.fit([X1_tensor, X2_tensor], y_tensor, batch_size=32, epochs=10, validation_split=0.2)

def predict_similarity(file1, file2):
    preprocessed_1 = preprocess_audio(file1)  # Shape (1, 128, 128, 1)
    preprocessed_2 = preprocess_audio(file2)  # Shape (1, 128, 128, 1)

    if preprocessed_1 is None or preprocessed_2 is None:
        print("Error processing files")
        return None

    # Pass both preprocessed inputs to the Siamese model
    similarity = siamese_model.predict([preprocessed_1, preprocessed_2])

    # The output is the similarity score
    return similarity[0][0]  # Extract the score from the output

test_file1 = "/content/drive/MyDrive/Datasets/vox_indian/id10003/5ablueV_1tw/00001.wav"
test_file2 = "/content/drive/MyDrive/Datasets/vox_indian/id10724/DP5gCFoWgGI/00002.wav"

similarity = predict_similarity(test_file1, test_file2)
print(f"Similarity Score: {similarity:.2f} (1.0 = identical, -1.0 = completely different)")
if similarity>0.8:
  print("pretty confident its the same speaker!")
else:
  print("not so sure about that one buddy")

