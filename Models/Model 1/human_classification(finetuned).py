# -*- coding: utf-8 -*-
"""human_classification(finetuned).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wK0NEPMwkwp4ci4TJQfnVGrcryis7nTE
"""

import os
import librosa
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers,models
import random

def fetch_audio(base_dir):

    audio_files = []
    for root, _, files in os.walk(base_dir):
        for file in files:
            if file.endswith(".wav"):
                audio_files.append(os.path.join(root, file))
    return audio_files

base_dir = "/content/drive/MyDrive/Datasets/vox_indian"
audio_files = fetch_audio(base_dir)
print(f"Found {len(audio_files)} audio files.")

def plot_mel_spectrogram(file_path, sr=16000, n_mels=128, hop_length=512):

    y, sr = librosa.load(file_path, sr=sr)
    y = librosa.util.fix_length(y, size=3 * sr)  # Trim/pad to 3 seconds

    # Compute mel-spectrogram
    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, hop_length=hop_length)
    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)  # Convert to dB

    # Plot
    plt.figure(figsize=(10, 4))
    librosa.display.specshow(mel_spec_db, sr=sr, hop_length=hop_length,
                             x_axis='time', y_axis='mel', cmap='viridis')
    plt.colorbar(format='%+2.0f dB')
    plt.title(f"Mel-Spectrogram: {os.path.basename(file_path)}")
    plt.show()

base_dir = "/content/drive/MyDrive/Datasets/vox_indian"
if not os.path.exists(base_dir):
    print(f"Error: Directory '{base_dir}' not found.")
else:
    audio_files = [os.path.join(root, f) for root, _, files in os.walk(base_dir) for f in files if f.endswith(".wav")]

    if not audio_files:
        print(f"Error: No .wav files found in '{base_dir}'.")
    else:
        for file_path in np.random.choice(audio_files, 3, replace=False):  # Pick 3 random files without replacement
            plot_mel_spectrogram(file_path)

from concurrent.futures import ThreadPoolExecutor  # For parallel processing
from tqdm import tqdm

'''def preprocess_audio(file_path, target_shape=(128, 128), sr=16000, n_mels=128, hop_length=512):
    y, _ = librosa.load(file_path, sr=sr, mono=True, dtype=np.float32)
    y = librosa.util.fix_length(y, size=3 * sr)  # Trim/pad to 3 seconds

    # Computing mel-spectrogram now
    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, hop_length=hop_length)
    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)

    # Normalize
    mel_spec_db = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-6) #0 to 1 scale normalized

    # Resize if needed
    if mel_spec_db.shape[1] != target_shape[1]:
        mel_spec_db = np.pad(mel_spec_db, ((0, 0), (0, max(0, target_shape[1] - mel_spec_db.shape[1]))), mode='constant')

    return mel_spec_db[..., np.newaxis]  # Add channel dimension'''

def preprocess_audio(file_path, target_shape=(128, 128), sr=16000, n_mels=128, hop_length=512):
    y, _ = librosa.load(file_path, sr=sr, mono=True, dtype=np.float32)
    y = librosa.util.fix_length(y, size=3 * sr)  # Trim/pad to 3 seconds

    # Compute mel-spectrogram
    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, hop_length=hop_length)
    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)

    # Normalize
    mel_spec_db = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-6)

    # Resize if needed
    if mel_spec_db.shape[1] != target_shape[1]:
        mel_spec_db = np.pad(mel_spec_db, ((0, 0), (0, max(0, target_shape[1] - mel_spec_db.shape[1]))), mode='constant')

    # Repeat single channel across 3 channels
    mel_spec_db = np.repeat(mel_spec_db[..., np.newaxis], 3, axis=-1)  # Shape: (128, 128, 3)

    return mel_spec_db

def preprocess_to_numpy_parallel(audio_files, target_shape=(128, 128), sr=16000, n_mels=128, hop_length=512, num_workers=4):
    mel_specs = []

    # Use ThreadPoolExecutor for parallel processing
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        # Submit tasks to the executor
        futures = [executor.submit(preprocess_audio, file_path, target_shape, sr, n_mels, hop_length) for file_path in audio_files]

        # Collect results with a progress bar
        for future in tqdm(futures, desc="Processing audio files", unit="file"):
            mel_specs.append(future.result())

    return np.array(mel_specs, dtype=np.float32)  # Use float32 for efficiency

mel_specs = preprocess_to_numpy_parallel(audio_files, num_workers=8)  # Use 8 workers
print(mel_specs.shape)

# Example: Print file paths and labels for the first 5 files
for i, file_path in enumerate(audio_files[:5]):
    label = os.path.basename(os.path.dirname(os.path.dirname(file_path)))
    print(f"File: {file_path} → Label: {label}")

# Extract labels correctly from the directory structure
labels = []
for file_path in audio_files:
    label = os.path.basename(os.path.dirname(os.path.dirname(file_path)))
    labels.append(label)

# filtering out skipped files if any
valid_indices = [i for i, spec in enumerate(mel_specs) if spec is not None]
audio_files = [audio_files[i] for i in valid_indices]
labels = [labels[i] for i in valid_indices]

import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

df = pd.DataFrame({"file_path": audio_files, "label": labels})

# Encode labels to integers (e.g., "id_01" → 0, "id_02" → 1)
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df["label_encoded"] = le.fit_transform(df["label"])

# Split into train/test
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

# Preprocess all files
X_train = np.array([preprocess_audio(fp) for fp in train_df["file_path"]])


X_test = np.array([preprocess_audio(fp) for fp in test_df["file_path"]])

num_classes = len(df["label_encoded"].unique())
y_train = to_categorical(train_df["label_encoded"], num_classes=num_classes)
y_test = to_categorical(test_df["label_encoded"], num_classes=num_classes)

print("Train shape:", X_train.shape)  # (num_samples, 128, 128, 3)
print("Test shape:", X_test.shape)

print("Unique labels in y_train:", np.unique(y_train))
print("Unique labels in y_test:", np.unique(y_test))

"""Imbalanced Classes as seen below

"""

import matplotlib.pyplot as plt

# Plot label distribution
plt.hist(y_train, bins=len(np.unique(y_train)))
plt.title("Label Distribution in Training Data")
plt.xlabel("Label")
plt.ylabel("Count")
plt.show()

import matplotlib.pyplot as plt

# Plot a few mel-spectrograms
for i in range(3):
    plt.imshow(X_train[i].squeeze(), cmap='viridis', origin='lower')
    plt.title(f"Label: {y_train[i]}")
    plt.colorbar()
    plt.show()

!pip install keras-tuner

import tensorflow as tf
from tensorflow.keras import layers, models

# Load Pretrained VGG Model (Feature Extractor)
vgg = tf.keras.applications.VGG16(
    include_top=False, input_shape=(128, 128, 3), weights="imagenet"
)

# Unfreeze last few layers for fine-tuning
for layer in vgg.layers[-4:]:
    layer.trainable = True

# Define Model
def vgg_dnn_model(num_classes=10):
    model = models.Sequential([
        vgg,
        layers.Flatten(),
        layers.Dense(512,activation="relu"),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(256, activation="relu"),
        layers.BatchNormalization(),
        layers.Dropout(0.5),  # Grid Search for dropout
        layers.Dense(num_classes, activation="softmax")
    ])
    return model

vgg_dnn = vgg_dnn_model(num_classes=num_classes)
vgg_dnn.summary()

import tensorflow as tf
from tensorflow.keras import layers, models
import keras_tuner as kt

# Load Pretrained VGG Model (Feature Extractor)
vgg = tf.keras.applications.VGG16(
    include_top=False, input_shape=(128, 128, 3), weights="imagenet"
)

# Unfreeze last few layers for fine-tuning
for layer in vgg.layers[-4:]:
    layer.trainable = True

# Define Model-Building Function for Keras Tuner
def build_model(hp):
    model = models.Sequential([
        vgg,  # VGG16 feature extractor (includes BatchNorm layers)
        layers.Flatten(),
        layers.Dense(hp.Choice("dense_units_1", [256, 512, 1024]), activation="relu"),
    ])

    # Optionally add BatchNorm in the custom DNN
    if hp.Boolean("use_batch_norm"):
        model.add(layers.BatchNormalization())

    # Add Dropout
    model.add(layers.Dropout(hp.Choice("dropout_1", [0.3, 0.4, 0.5])))

    # Add another Dense layer
    model.add(layers.Dense(hp.Choice("dense_units_2", [128, 256, 512]), activation="relu"))

    # Optionally add BatchNorm in the custom DNN
    if hp.Boolean("use_batch_norm"):
        model.add(layers.BatchNormalization())

    # Add Dropout
    model.add(layers.Dropout(hp.Choice("dropout_2", [0.3, 0.4, 0.5])))

    # Output layer
    model.add(layers.Dense(num_classes, activation="softmax"))
    # Compile the model
    model.compile(
        optimizer=tf.keras.optimizers.Adam(
            learning_rate=hp.Choice("learning_rate", [1e-4, 1e-3])
        ),
        loss="categorical_crossentropy",
        metrics=["accuracy"]
    )
    return model

# Initialize Keras Tuner (RandomSearch)
tuner = kt.RandomSearch(
    build_model,
    objective="val_accuracy",
    max_trials=10,  # Number of hyperparameter combinations to try
    directory="tuning",  # Directory to save tuning results
    project_name="vgg_dnn_tuning"  # Name of the tuning project
)

# Run the hyperparameter search
tuner.search(
    X_train, y_train,
    epochs=10,  # Use fewer epochs for tuning (increase later for final training)
    validation_data=(X_test, y_test)
)

# Get the best hyperparameters
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
print(f"Best Hyperparameters: {best_hps}")

# Build the best model
best_model = tuner.hypermodel.build(best_hps)

# Train the best model on the full dataset
history = best_model.fit(
    X_train, y_train,
    epochs=20,  # Use more epochs for final training
    validation_data=(X_test, y_test)
)

# Evaluate the best model on the test set
test_loss, test_accuracy = best_model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_accuracy}")

print(f"Test Loss: {test_loss:.4f}")

best_model.summary()

import matplotlib.pyplot as plt

def plot_training_results(history):
    plt.figure(figsize=(12, 5))

    # Plot Accuracy
    plt.subplot(1, 2, 1)
    plt.plot(history.history["accuracy"], label="Train Accuracy")
    plt.plot(history.history["val_accuracy"], label="Validation Accuracy")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.title("Training vs. Validation Accuracy")

    # Plot Loss
    plt.subplot(1, 2, 2)
    plt.plot(history.history["loss"], label="Train Loss")
    plt.plot(history.history["val_loss"], label="Validation Loss")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.legend()
    plt.title("Training vs. Validation Loss")

    plt.show()

# Call the function
plot_training_results(history)

from sklearn.metrics import confusion_matrix
import seaborn as sns
import numpy as np

# Get predictions
y_pred = best_model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

if len(y_test.shape) > 1 and y_test.shape[1] > 1:  # Check if one-hot encoded
    y_true_classes = np.argmax(y_test, axis=1)
else:
    y_true_classes = y_test

# Compute confusion matrix
cm = confusion_matrix(y_true, y_pred_classes)

# Plot confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

from sklearn.metrics import classification_report

print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))

#Precision: How many predicted labels were correct?
#Recall: How many true labels were detected correctly?
#F1-Score: Balance between precision & recall.









# Plot training curves
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Evaluate on test data

test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_acc * 100:.2f}%")

from sklearn.metrics import confusion_matrix
import seaborn as sns
sns.set()

y_predicted = model.predict(X_test)
# y_test is 1-dimensional
mat = confusion_matrix(y_test, y_predicted.argmax(axis=1))
class_labels = le.classes_  # Assuming 'le' is your LabelEncoder
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,
            xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('true label')
plt.ylabel('predicted label');

# After training your CNN
import pickle
model.save('cnn_speaker_classifier.h5')
with open('label_encoder.pkl', 'wb') as f:
    pickle.dump(le, f)

import tensorflow as tf
import librosa
import numpy as np
import pickle
import os

# 1. Load your trained model and label encoder
model = tf.keras.models.load_model('cnn_speaker_classifier.h5')
with open('label_encoder.pkl', 'rb') as f:
    le = pickle.load(f)

def preprocess_audio(file_path, target_shape=(128, 128), sr=16000):
    try:
        y, _ = librosa.load(file_path, sr=sr)
        y = librosa.util.fix_length(y, size=3 * sr)

        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr,
                                                 n_mels=target_shape[0],
                                                 hop_length=512)
        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)
        mel_spec_db = (mel_spec_db - mel_spec_db.min()) / \
                     (mel_spec_db.max() - mel_spec_db.min() + 1e-6)
        mel_spec_db = tf.image.resize(mel_spec_db[None, ..., None], target_shape[:2]).numpy().squeeze()
        return np.expand_dims(mel_spec_db[..., np.newaxis], axis=0)  # Shape is (1, 128, 128, 1)

    except Exception as e:
        print(f"Error processing {file_path}: {str(e)}")
        return None

def predict_audio_class(file_path):
    preprocessed = preprocess_audio(file_path)

    predictions = model.predict(preprocessed)
    predicted_index = np.argmax(predictions[0])
    confidence = np.max(predictions[0])

    predicted_class = le.inverse_transform([predicted_index])[0]
    return predicted_class, confidence

test_file = "/content/drive/MyDrive/Datasets/vox_indian/id10393/DMBVJM39ybM/00004.wav"
if os.path.exists(test_file):
    class_name, confidence = predict_audio_class(test_file)
    MIN_CONFIDENCE = 0.7
    if confidence < MIN_CONFIDENCE:
        print("Uncertain prediction - might be an unknown speaker!")
        print(f"Predicted class: {class_name} | Confidence: {confidence:.2%}")
    else:
        print(f"Predicted class: {class_name} | Confidence: {confidence:.2%}")
else:
    print("File not found!")

from google.colab import drive
drive.mount('/content/drive')

model.save('/content/drive/MyDrive/cnn_speaker_classifier.h5')

import pickle

# Save the label encoder to Google Drive
label_encoder_path = "/content/drive/MyDrive/label_encoder.pkl"
with open(label_encoder_path, "wb") as f:
    pickle.dump(le, f)

print("Label encoder saved successfully!")

