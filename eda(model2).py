# -*- coding: utf-8 -*-
"""EDA(model2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-J_zmoGdRplggeaBMHiGw5GvvB4jyeXg
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import pandas as pd
import numpy as np

!unzip /content/drive/MyDrive/Datasets/animals.zip

!unzip /content/drive/MyDrive/Datasets/birds.zip

!unzip /content/drive/MyDrive/Datasets/FSC22.zip

!pip install pydub
!apt-get install ffmpeg

from pydub import AudioSegment
import os

def check_corrupted_mp3_files(folder_path):
    corrupted_files = []
    for root, dirs, files in os.walk(folder_path):
        for file in files:
            if file.endswith(".mp3"):
                file_path = os.path.join(root, file)
                try:
                    # Attempt to load the file
                    audio = AudioSegment.from_mp3(file_path)
                except Exception as e:
                    #print(f"Corrupted file: {file_path} - Error: {e}")
                    corrupted_files.append(file_path)
    return corrupted_files

# Path to your dataset
dataset_path = "/content/BirdsSound"

# Check for corrupted files
corrupted_files = check_corrupted_mp3_files(dataset_path)

def convert_mp3_to_wav(dataset_path, output_path):
    # Create output directory if it doesn't exist
    if not os.path.exists(output_path):
        os.makedirs(output_path)

    # Iterate through the dataset directory
    for root, dirs, files in os.walk(dataset_path):
        for file in files:
            if file.endswith(".mp3"):  # Check for MP3 files
                file_path = os.path.join(root, file)
                try:
                    # Convert MP3 to WAV
                    audio = AudioSegment.from_mp3(file_path)
                    # Create output subdirectory if it doesn't exist
                    relative_path = os.path.relpath(root, dataset_path)
                    output_subdir = os.path.join(output_path, relative_path)
                    if not os.path.exists(output_subdir):
                        os.makedirs(output_subdir)
                    # Save as WAV
                    wav_file_path = os.path.join(output_subdir, file.replace(".mp3", ".wav"))
                    audio.export(wav_file_path, format="wav")
                    print(f"Converted {file_path} to {wav_file_path}")
                except Exception as e:
                    print(f"Skipping corrupted file: {file_path} - Error: {e}")

# Paths
birds_mp3_path = "/content/BirdsSound"  # Path to the Birds dataset (MP3 files)
birds_wav_path = "/content/BirdsSoundWAV"  # Path to save converted WAV files

# Convert MP3 to WAV (skip corrupted files)
convert_mp3_to_wav(birds_mp3_path, birds_wav_path)

import librosa

def check_audio_durations(dataset_path):
    durations = []
    for label in os.listdir(dataset_path):
        label_path = os.path.join(dataset_path, label)
        if os.path.isdir(label_path):
            for file in os.listdir(label_path):
                if file.endswith(".wav"):
                    file_path = os.path.join(label_path, file)
                    # Load the audio file and get its duration
                    audio, sr = librosa.load(file_path, sr=None)
                    duration = librosa.get_duration(y=audio, sr=sr)
                    durations.append(duration)
    return durations

# Check durations for each dataset
fsc22_durations = check_audio_durations("/content/Audio Wise V1.0-20220916T202003Z-001")
birds_durations = check_audio_durations("/content/BirdsSoundWAV")
animal_durations = check_audio_durations("/content/Animal-Soundprepros")

# Print statistics
print("FSC22 Durations - Min:", min(fsc22_durations), "Max:", max(fsc22_durations), "Mean:", np.mean(fsc22_durations))
print("Birds Durations - Min:", min(birds_durations), "Max:", max(birds_durations), "Mean:", np.mean(birds_durations))
print("Animal Durations - Min:", min(animal_durations), "Max:", max(animal_durations), "Mean:", np.mean(animal_durations))

def load_and_fix_duration(file_path, target_duration=5.0, sr=22050):
    try:
        # Load the audio file
        audio, sr = librosa.load(file_path, sr=sr, duration=target_duration)
        # If the audio is shorter than the target duration, pad it with silence
        if len(audio) < int(target_duration * sr):
            padding = int(target_duration * sr) - len(audio)
            audio = np.pad(audio, (0, padding), mode='constant')
        return audio, sr
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None, None

def segment_audio(audio, sr, segment_duration=5.0):
    segment_length = int(segment_duration * sr)
    num_segments = len(audio) // segment_length
    segments = []
    for i in range(num_segments):
        start = i * segment_length
        end = start + segment_length
        segment = audio[start:end]
        segments.append(segment)
    return segments

def extract_features_from_audio(audio, sr, n_mfcc=40, max_pad_len=100):
    try:
        # Extract MFCCs
        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)
        # Pad or truncate the MFCCs to a fixed length
        pad_width = max_pad_len - mfccs.shape[1]
        if pad_width > 0:
            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')
        else:
            mfccs = mfccs[:, :max_pad_len]
    except Exception as e:
        print(f"Error extracting features: {e}")
        return None
    return mfccs

def preprocess_paddedandtuncated_dataset(dataset_path, target_duration=5.0):
    features = []
    labels = []

    for label in os.listdir(dataset_path):
        label_path = os.path.join(dataset_path, label)
        if os.path.isdir(label_path):  # Ensure it's a folder
            for file in os.listdir(label_path):
                if file.endswith(".wav"):  # Check for WAV files
                    file_path = os.path.join(label_path, file)
                    # Load and fix duration
                    audio, sr = load_and_fix_duration(file_path, target_duration)
                    if audio is not None:
                        # If the audio is longer than the target duration, segment it
                        if len(audio) > int(target_duration * sr):
                            segments = segment_audio(audio, sr, target_duration)
                            for segment in segments:
                                feature = extract_features_from_audio(segment, sr)
                                if feature is not None:
                                    features.append(feature)
                                    labels.append(label)
                        else:
                            feature = extract_features_from_audio(audio, sr)
                            if feature is not None:
                                features.append(feature)
                                labels.append(label)
    return np.array(features), np.array(labels)

animal_dataset_path="/content/Animal-Soundprepros"
animal_features, animal_labels = preprocess_paddedandtuncated_dataset(animal_dataset_path)

birds_dataset_path="/content/BirdsSoundWAV"
birds_features, birds_labels = preprocess_paddedandtuncated_dataset(birds_dataset_path)

metadata_path = "/content/Metadata-20220916T202011Z-001/Metadata/Metadata V1.0 FSC22.csv"
metadata = pd.read_csv(metadata_path)

audio_folder = "/content/Audio Wise V1.0-20220916T202003Z-001/Audio Wise V1.0"

ambient_features = []
ambient_labels = []


def extract_features(file_path, max_pad_len=100):
    try:
        # Load the audio file
        audio, sample_rate = librosa.load(file_path, sr=22050)
        # Extract MFCCs (you can also use other features like spectrograms)
        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40,fmax=11025)
        # Pad or truncate the MFCCs to a fixed length
        pad_width = max_pad_len - mfccs.shape[1]
        if pad_width > 0:
            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')
        else:
            mfccs = mfccs[:, :max_pad_len]
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None
    return mfccs
for index, row in metadata.iterrows():
    file_name = row['Dataset File Name']
    label = row['Class Name']
    file_path = os.path.join(audio_folder, file_name)

    # Extract features from the audio file
    feature = extract_features(file_path)
    if feature is not None:
        ambient_features.append(feature)
        ambient_labels.append(label)

ambient_features = np.array(ambient_features)
ambient_labels = np.array(ambient_labels)

X = np.concatenate([ambient_features, animal_features, birds_features], axis=0)
y = np.concatenate([ambient_labels, animal_labels, birds_labels], axis=0)

