# -*- coding: utf-8 -*-
"""human_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wK0NEPMwkwp4ci4TJQfnVGrcryis7nTE
"""

import os
import librosa
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers
import random

def fetch_audio(base_dir):

    audio_files = []
    for root, _, files in os.walk(base_dir):
        for file in files:
            if file.endswith(".wav"):
                audio_files.append(os.path.join(root, file))
    return audio_files

base_dir = "/content/drive/MyDrive/Datasets/vox_indian"
audio_files = fetch_audio(base_dir)
print(f"Found {len(audio_files)} audio files.")

import os
import librosa
import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers
import random

def plot_mel_spectrogram(file_path, sr=16000, n_mels=128, hop_length=512):

    y, sr = librosa.load(file_path, sr=sr)
    y = librosa.util.fix_length(y, size=3 * sr)  # Trim/pad to 3 seconds

    # Compute mel-spectrogram
    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, hop_length=hop_length)
    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)  # Convert to dB

    # Plot
    plt.figure(figsize=(10, 4))
    librosa.display.specshow(mel_spec_db, sr=sr, hop_length=hop_length,
                             x_axis='time', y_axis='mel', cmap='viridis')
    plt.colorbar(format='%+2.0f dB')
    plt.title(f"Mel-Spectrogram: {os.path.basename(file_path)}")
    plt.show()

base_dir = "/content/drive/MyDrive/Datasets/vox_indian"
if not os.path.exists(base_dir):
    print(f"Error: Directory '{base_dir}' not found.")
else:
    audio_files = [os.path.join(root, f) for root, _, files in os.walk(base_dir) for f in files if f.endswith(".wav")]

    if not audio_files:
        print(f"Error: No .wav files found in '{base_dir}'.")
    else:
        for file_path in np.random.choice(audio_files, 3, replace=False):  # Pick 3 random files without replacement
            plot_mel_spectrogram(file_path)

import librosa
import numpy as np
from concurrent.futures import ThreadPoolExecutor  # For parallel processing
from tqdm import tqdm  # For progress bar

def preprocess_audio(file_path, target_shape=(128, 128), sr=16000, n_mels=128, hop_length=512):
    y, _ = librosa.load(file_path, sr=sr, mono=True, dtype=np.float32)  # Load in float32
    y = librosa.util.fix_length(y, size=3 * sr)  # Trim/pad to 3 seconds

    # Compute mel-spectrogram
    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, hop_length=hop_length)
    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)

    # Normalize
    mel_spec_db = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-6)

    # Resize if needed
    if mel_spec_db.shape[1] != target_shape[1]:
        mel_spec_db = np.pad(mel_spec_db, ((0, 0), (0, max(0, target_shape[1] - mel_spec_db.shape[1]))), mode='constant')

    return mel_spec_db[..., np.newaxis]  # Add channel dimension

def preprocess_to_numpy_parallel(audio_files, target_shape=(128, 128), sr=16000, n_mels=128, hop_length=512, num_workers=4):
    mel_specs = []

    # Use ThreadPoolExecutor for parallel processing
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        # Submit tasks to the executor
        futures = [executor.submit(preprocess_audio, file_path, target_shape, sr, n_mels, hop_length) for file_path in audio_files]

        # Collect results with a progress bar
        for future in tqdm(futures, desc="Processing audio files", unit="file"):
            mel_specs.append(future.result())

    return np.array(mel_specs, dtype=np.float32)  # Use float32 for efficiency

mel_specs = preprocess_to_numpy_parallel(audio_files, num_workers=8)  # Use 8 workers
print(mel_specs.shape)

print(audio_files[:5])  # Print the first 5 file paths
print(len(audio_files), len(labels))

# Example: Print file paths and labels for the first 5 files
for i, file_path in enumerate(audio_files[:5]):
    label = os.path.basename(os.path.dirname(os.path.dirname(file_path)))
    print(f"File: {file_path} → Label: {label}")

# Extract labels correctly from the directory structure
labels = []
for file_path in audio_files:
    # Get the grandparent directory of the file (id_xx)
    label = os.path.basename(os.path.dirname(os.path.dirname(file_path)))
    labels.append(label)

# Example: Print file paths and labels for the first 5 files
for i, file_path in enumerate(audio_files[:5]):
    label = os.path.basename(os.path.dirname(os.path.dirname(file_path)))
    print(f"File: {file_path} → Label: {label}")

# After preprocessing, filter out skipped files
valid_indices = [i for i, spec in enumerate(mel_specs) if spec is not None]
audio_files = [audio_files[i] for i in valid_indices]
labels = [labels[i] for i in valid_indices]

df = pd.DataFrame({"file_path": audio_files, "label": labels})

import pandas as pd
from sklearn.model_selection import train_test_split

df = pd.DataFrame({"file_path": audio_files, "label": labels})

# Encode labels to integers (e.g., "id_01" → 0, "id_02" → 1)
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df["label_encoded"] = le.fit_transform(df["label"])

# Split into train/test
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

# Preprocess all files (slow but simple)
X_train = np.array([preprocess_audio(fp) for fp in train_df["file_path"]])
y_train = train_df["label_encoded"].values

X_test = np.array([preprocess_audio(fp) for fp in test_df["file_path"]])
y_test = test_df["label_encoded"].values

print("Train shape:", X_train.shape)  # (num_samples, 128, 128, 1)
print("Test shape:", X_test.shape)

print("Unique labels in y_train:", np.unique(y_train))
print("Unique labels in y_test:", np.unique(y_test))

"""Imbalanced Classes as seen below

"""

import matplotlib.pyplot as plt

# Plot label distribution
plt.hist(y_train, bins=len(np.unique(y_train)))
plt.title("Label Distribution in Training Data")
plt.xlabel("Label")
plt.ylabel("Count")
plt.show()

import matplotlib.pyplot as plt

# Plot a few mel-spectrograms
for i in range(3):
    plt.imshow(X_train[i].squeeze(), cmap='viridis', origin='lower')
    plt.title(f"Label: {y_train[i]}")
    plt.colorbar()
    plt.show()

from tensorflow.keras import layers, models

model = models.Sequential([
    layers.Input(shape=(128, 128, 1)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(len(le.classes_), activation='softmax')  # Output neurons = num speakers
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Plot training curves
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Evaluate on test data
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_acc * 100:.2f}%")



